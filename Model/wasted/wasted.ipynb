{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMroxvpv8FnDq3rxE/K+0iW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"xdBEgQzrtGZZ","executionInfo":{"status":"ok","timestamp":1710767784957,"user_tz":-480,"elapsed":10,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"outputs":[],"source":["# check = {\"test\" : 2}\n","\n","# torch.save(checkpoint, 'test1.pth')\n","# source_path = 'test1.pth'\n","# destination_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Data/data_zip_shuffle'\n","# shutil.copy(source_path, destination_path)"]},{"cell_type":"code","source":["# check2 = torch.load('/content/drive/MyDrive/Colab Notebooks/Simple_DE/Data/data_zip_shuffle/test1.pth')\n","# check2['test']"],"metadata":{"id":"dhu-Ht_2tJy4","executionInfo":{"status":"ok","timestamp":1710767784958,"user_tz":-480,"elapsed":10,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# ori_data_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Data/name_zip_shuffle'\n","# ori_data_path = ori_data_path + '/' + 'dataset_1.pth'\n","# check = torch.load(ori_data_path)\n"],"metadata":{"id":"cyp6JSgltLc-","executionInfo":{"status":"ok","timestamp":1710767791849,"user_tz":-480,"elapsed":3,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# print(check['depth_name'][:20])\n","# print(check['depth_name'][-20:])"],"metadata":{"id":"fAZR9MrKtNq5","executionInfo":{"status":"ok","timestamp":1710767796079,"user_tz":-480,"elapsed":3,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# # shuffle dataset\n","# data_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Data/data_zip_shuffle/dataset_1.pth_2'\n","\n","# new_file_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Data/data_zip_shuffle/dataset_1.pth_3'\n","# # os.rename(data_path, new_file_path)\n","# data_path = new_file_path\n","# os.remove(data_path)\n"],"metadata":{"id":"m4G6apQjtOxT","executionInfo":{"status":"ok","timestamp":1710767803056,"user_tz":-480,"elapsed":3,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["'''\n","path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Data/data_zip'\n","total_sum, total_nonzero, total_mean = compute_depth_mean(path)\n","print(total_sum, total_nonzero, total_mean)\n","'''"],"metadata":{"id":"eeW3JLK2tQYH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","std_square = compute_depth_std(path, total_mean, total_nonzero)\n","print(std_square)\n","'''"],"metadata":{"id":"5JgkcxKDuycu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","checkpoint = {\n","          'total_sum': total_sum,\n","          'total_nonzero': total_nonzero, # model.state_dict()是存下param的的值和形狀\n","          'total_mean': total_mean, # optimizer.state_dict()則是存下優化器的param如momentum等等 不包含當下梯度\n","          'total_std' : total_std\n","        }\n","\n","torch.save(checkpoint, 'depth_analysis2.pth')\n","source_path = 'depth_analysis2.pth'\n","destination_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Model'\n","shutil.copy(source_path, destination_path)\n","'''"],"metadata":{"id":"_O9nk3xKvH_D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","def find_next_file(first, second):\n","  first_list = sorted(os.listdir(first))\n","  second_list = sorted(os.listdir(second))\n","  length = len(first_list)\n","  while True:\n","    rand_int = random.randint(0, length - 1)\n","    target = first_list[rand_int]\n","    if target in second_list:\n","      return first + '/' + target, second + '/' + target\n","'''"],"metadata":{"id":"d_cQBFgZvK99"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","def create_dataset_save(first_path, second_path, epoch_size = 5000): # first is depth, second is image\n","  depth_list = []\n","  image_list = []\n","  depth_name_list = []\n","  image_name_list = []\n","  count = 0\n","  file_count = 8  #改\n","\n","  first_path_list1 = sorted(os.listdir(first_path))\n","  second_path_list1 = sorted(os.listdir(second_path))\n","  idx1_start = 109   #改\n","\n","  for idx1 in range(idx1_start, len(first_path_list1)):\n","\n","    first_seq1 = first_path_list1[idx1]\n","    # if first_seq1 == '2011_09_28_drive_0090_sync': #改\n","    #   continue\n","    first_path2 = first_path + '/' + first_seq1 + '/proj_depth/groundtruth'\n","    second_path2 = second_path + '/' + first_seq1\n","    first_path_list2 = sorted(os.listdir(first_path2))\n","\n","    if idx1 == idx1_start:\n","      idx2_start = 1  # 改\n","    else:\n","      idx2_start = 0\n","    for idx2 in range(idx2_start, len(first_path_list2)): # image02, image03\n","      first_seq2 = first_path_list2[idx2]\n","      first_path3 = first_path2 + '/' + first_seq2\n","      second_path3 = second_path2 + '/' + first_seq2 + '/data'\n","      first_path_list3 = sorted(os.listdir(first_path3))\n","      if idx1 == idx1_start and idx2 == idx2_start:\n","        idx3_start = 58 #改成+1\n","      else:\n","        idx3_start = 0\n","      for idx3 in range(idx3_start, len(first_path_list3)):\n","        first_seq3 = first_path_list3[idx3]\n","        first_path4 = first_path3 + '/' + first_seq3\n","        second_path4 = second_path3 + '/' + first_seq3\n","        print(count)\n","        print(first_path4)\n","        print(second_path4)\n","        if first_path4[-5] == ')':\n","          continue\n","        depth = np.array(Image.open(first_path4), dtype=np.int16)\n","        depth = cv2.resize(depth, target_size, cv2.INTER_LANCZOS4)\n","        depth = depth.astype(np.float16) / 256.0\n","\n","\n","        image = cv2.imread(second_path4)\n","\n","\n","        image = cv2.resize(image, target_size, interpolation = cv2.INTER_LANCZOS4)\n","        depth_list.append(depth)\n","        depth_name_list.append(first_path4)\n","        image_list.append(image)\n","        image_name_list.append(second_path4)\n","        count = count + 1\n","\n","\n","        if count == epoch_size:\n","          count = 0\n","          checkpoint = {\n","              'depth_list': depth_list,\n","              'image_list' : image_list,\n","          }\n","          checkpoint2 = {\n","              'depth_name' : depth_name_list,\n","              'image_name' : image_name_list\n","          }\n","          name = 'dataset_{}.pth'.format(file_count)\n","          name2 = 'name_list_{}.pth'.format(file_count)\n","          file_count = file_count + 1\n","          torch.save(checkpoint, name)\n","          torch.save(checkpoint2, name2)\n","          source_path = name\n","          source_path2 = name2\n","          destination_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Data/data_zip'    # 要改\n","          destination_path2 = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Data/name_zip'\n","\n","          shutil.copy(source_path, destination_path)\n","          shutil.copy(source_path2, destination_path2)\n","\n","          depth_name_list = []\n","          image_name_list = []\n","          depth_list = []\n","          image_list = []\n","\n","'''"],"metadata":{"id":"lde3AewkvOPW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","first_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Data/Depth'\n","second_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Data/Image'\n","create_dataset_save(first_path, second_path, epoch_size = 5000) # first is depth, second is image\n","\n","from google.colab import runtime\n","runtime.unassign()\n","'''"],"metadata":{"id":"Mo3NwAwHvRxS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","image_name_list = checkpoint['depth_name']\n","depth_name_list = checkpoint['depth_name']\n","print(depth_name_list[4999])\n","'''"],"metadata":{"id":"-0gO4HzrvT9S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","def create_dataset(data_per_epoch, amount_from_file, path): #data_per_epoch / amount_from_file要是整數\n","\n","  name_list = sorted(os.listdir(path))\n","\n","  if data_per_epoch % amount_from_file != 0:\n","    print(\"error, data_per_epoch can't divide amount_from_file !!!!!\")\n","    sys.exit(1)\n","\n","  file_idx = data_per_epoch // amount_from_file\n","\n","  output_depth = []\n","  output_image = []\n","  length = len(name_list)\n","  for idx in range(file_idx):\n","    rand_int = random.randint(0, length - 1)\n","    tmp_file = name_list[rand_int]\n","    name = path + '/' + tmp_file\n","    checkpoint = torch.load(name)\n","    depth_list = checkpoint['depth_list']\n","    image_list = checkpoint['image_list']\n","    length_inside = len(depth_list)\n","    random_number = torch.randint(0, length_inside, (amount_from_file, ))\n","\n","    for jdx in range(amount_from_file):\n","\n","      output_depth.append(depth_list[random_number[jdx]])\n","      output_image.append(image_list[random_number[jdx]])\n","  return output_image, output_depth\n","\n","'''"],"metadata":{"id":"IQZsaxIJvfcV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","def create_dataset_for_debug(data_per_epoch, amount_from_file, path): #data_per_epoch / amount_from_file要是整數\n","  name_list = sorted(os.listdir(path))\n","  file_idx = data_per_epoch // amount_from_file\n","  output_depth_path = []\n","  output_image_path = []\n","  output_depth = []\n","  output_image = []\n","  sym = 0\n","  if data_per_epoch % amount_from_file  != 0:\n","    file_idx = file_idx + 1\n","    sym = 1\n","  length = len(name_list)\n","  for idx in range(file_idx):\n","    rand_int = random.randint(0, length - 1)\n","    tmp_file = name_list[rand_int]\n","    name = path + '/' + tmp_file\n","    checkpoint = torch.load(name)\n","    depth_list = checkpoint['depth_list']\n","    image_list = checkpoint['image_list']\n","    length_inside = len(depth_list)\n","    if sym == 1:\n","      if idx == file_idx - 1:\n","\n","        random_number = torch.randint(0, length_inside, ((data_per_epoch % amount_from_file), ))\n","      else:\n","\n","        random_number = torch.randint(0, length_inside, (amount_from_file, ))\n","\n","\n","    else:\n","      random_number = torch.randint(0, length_inside, (amount_from_file, ))\n","    for jdx in range(amount_from_file):\n","\n","      output_depth.append(depth_list[random_number[jdx]])\n","      output_image.append(image_list[random_number[jdx]])\n","  return output_image, output_depth\n","\n","'''"],"metadata":{"id":"1hySSuMHvhgK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","data_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Data/data_zip'\n","name_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Data/name_zip'\n","random_list = []\n","\n","check_length = len(sorted(os.listdir(data_path)))\n","for idx in range(1, check_length + 1):\n","  random_list.append(idx)\n","random.shuffle(random_list)\n","now = 2 # 實際上now也要從0一路走到最大值\n","\n","\n","output_image_path, output_depth_path, output_depth, output_image = create_dataset_large_epoch(random_list, now, data_path, name_path)\n","'''"],"metadata":{"id":"e7Z0BC34vrRq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","custom_dataset = CustomDataset(output_image, output_depth)\n","train_size = int(0.9 * len(custom_dataset))\n","val_size = len(custom_dataset) - train_size\n","train_dataset, val_dataset = random_split(custom_dataset, [train_size, val_size])\n","\n","batch_size = 128\n","\n","\n","trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last = True)\n","validloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, drop_last = True)\n","'''"],"metadata":{"id":"2J2byhBTz6ok"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","for batch in trainloader:\n","  print(batch['img'].shape)\n","  print(batch['img'].dtype)\n","  print(torch.max(batch['img']))\n","  print(torch.min(batch['img']))\n","  print(torch.mean(batch['img'].to(torch.float32)))\n","  print(batch['depth'].shape)\n","  print(batch['depth'].dtype)\n","  print(torch.max(batch['depth']))\n","  print(torch.min(batch['depth']))\n","  print(torch.mean(batch['depth']))\n","  break\n","'''"],"metadata":{"id":"Zjr_iVTc0ytW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for batch in trainloader:\n","\n","#   batch['img'] = image_loader_to_tensor(batch['img'])\n","#   batch['depth'] = depth_loader_to_tensor(batch['depth'], DEPTH_MEAN, DEPTH_STD)\n","#   break\n","# nonzero = batch['depth'] != -1\n","# print(batch['img'].shape)\n","# print(batch['img'].dtype)\n","# print(torch.max(batch['img']))\n","# print(torch.min(batch['img']))\n","# print(torch.mean(batch['img']))\n","# print(batch['depth'].shape)\n","# print(batch['depth'].dtype)\n","# print(torch.max(batch['depth'][nonzero]))\n","# print(torch.min(batch['depth'][nonzero]))\n","# print(torch.mean(batch['depth'][nonzero]))\n","# print(torch.std(batch['depth'][nonzero]))"],"metadata":{"id":"6CNUUrUX01Ge"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# this is min max normalize\n","'''\n","def depth_folder_to_tensor(folder_path):\n","\n","    images_list = []\n","\n","\n","\n","    files = sorted(os.listdir(folder_path))\n","\n","    for file in files:\n","\n","        file_path = os.path.join(folder_path, file)\n","        depth = np.array(Image.open(file_path), dtype=np.int16)\n","        assert(np.max(depth) > 255)\n","        depth = cv2.resize(depth, target_size, cv2.INTER_LANCZOS4)\n","        depth = depth.astype(np.float16) / 256.0\n","        images_list.append(depth)\n","\n","\n","\n","    img2 = np.stack(images_list, axis=0)\n","    tensor = torch.tensor(img2)\n","\n","    mini = torch.min(tensor[tensor != 0])\n","    tensor = (tensor - mini) / (tensor.max() - mini)\n","    tensor = torch.where(tensor < 0, -1, tensor)\n","\n","\n","\n","\n","\n","\n","    return tensor\n","'''"],"metadata":{"id":"PR2Utku809ON"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","# this is z-score normalization\n","\n","def depth_folder_to_tensor(folder_path):\n","\n","    images_list = []\n","\n","\n","\n","    files = sorted(os.listdir(folder_path))\n","\n","    for file in files:\n","\n","        file_path = os.path.join(folder_path, file)\n","        depth = np.array(Image.open(file_path), dtype=np.int16)\n","        assert(np.max(depth) > 255)\n","        depth = cv2.resize(depth, target_size, cv2.INTER_LANCZOS4)\n","        depth = depth.astype(np.float16) / 256.0\n","        images_list.append(depth)\n","\n","\n","\n","    img2 = np.stack(images_list, axis=0)\n","    tensor = torch.tensor(img2)\n","    nonzero_mask = tensor != 0\n","    zero_mask = tensor == 0\n","    mean = tensor[nonzero_mask].mean()\n","    std = tensor[nonzero_mask].std()\n","    result = (tensor[nonzero_mask] - mean) / std\n","    tensor[nonzero_mask] = result\n","    tensor[zero_mask] = -1\n","\n","\n","\n","    return tensor, mean, std\n","'''"],"metadata":{"id":"0geFocya1BTp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","def Normalize(in_channels):\n","    return torch.nn.GroupNorm(num_groups=32, num_channels=in_channels, eps=1e-6, affine=True)\n","'''"],"metadata":{"id":"7tAwFQ5B1LDH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def nonlinearity(input, negative_slope = 0.1, inplace = False):\n","#   return torch.nn.functional.leaky_relu(input_tensor, negative_slope = negative_slope, inplace = inplace)"],"metadata":{"id":"-ioUdOJM1ZKn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","class DiffusionModel:\n","    def __init__(self, beta_schedule = 'linear', start_schedule=0.0001, end_schedule=0.02, timesteps = 300):\n","        self.start_schedule = start_schedule\n","        self.end_schedule = end_schedule\n","        self.timesteps = timesteps\n","\n","        \"\"\"\n","        if\n","            betas = [0.1, 0.2, 0.3, ...]\n","        then\n","            alphas = [0.9, 0.8, 0.7, ...]\n","            alphas_cumprod = [0.9, 0.9 * 0.8, 0.9 * 0.8, * 0.7, ...]\n","\n","\n","        \"\"\"\n","        betas = get_beta_schedule(beta_schedule, beta_start = start_schedule, beta_end = end_schedule, num_diffusion_timesteps = timesteps)\n","        self.betas = torch.tensor(betas)\n","\n","\n","        self.alphas = 1 - self.betas\n","        self.alphas_cumprod = torch.cumprod(self.alphas, axis=0)\n","\n","    def forward(self, x_0, t, device):\n","        \"\"\"\n","        x_0: (B, C, H, W)\n","        t: (B,)\n","        \"\"\"\n","\n","\n","        noise = torch.randn_like(x_0)\n","\n","        sqrt_alphas_cumprod_t = get_index_from_list(self.alphas_cumprod.sqrt(), t.to(torch.int64), x_0.shape)\n","\n","        sqrt_one_minus_alphas_cumprod_t = get_index_from_list(torch.sqrt(1. - self.alphas_cumprod), t.to(torch.int64), x_0.shape)\n","\n","        mean = sqrt_alphas_cumprod_t.to(device) * x_0.to(device)\n","        variance = sqrt_one_minus_alphas_cumprod_t.to(device) * noise.to(device)\n","\n","        return mean + variance, noise.to(device) # mean為x_0乘以alpha bar, variance 為 noise 乘以 1-alpha bar\n","'''"],"metadata":{"id":"eViF_M6V1isD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","# analysis for model weights\n","path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Checkpoint/weight_save/weight_{}.pth'.format(113)\n","checkpoint = torch.load(path, map_location = device)\n","'''"],"metadata":{"id":"Nc8OCMtE2QpP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","# analysis for model weights\n","weights = checkpoint['model_state_dict']\n","'''\n"],"metadata":{"id":"FhpmYrN02RNF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","# analysis for model weights\n","print(\"number of keys : {}\".format(len(weights)))\n","for key, value in weights.items():\n","    print(key, \"\\t\", value.shape, \"min = {}\".format(torch.min(value)))\n","    print(\"------------\")\n","'''"],"metadata":{"id":"If2W6vgF2V9o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","# debug01 build dataset\n","\n","random_list = []\n","check_length = len(sorted(os.listdir(data_path)))\n","for idx in range(1, check_length + 1):\n","  random_list.append(idx)\n","now = 0\n","random.shuffle(random_list)\n","output_image_path, output_depth_path, output_depth, output_image = create_dataset_large_epoch(random_list, now, data_path, name_path)\n","\n","custom_dataset = CustomDataset(output_image, output_depth)\n","train_size = int(0.9 * len(custom_dataset))\n","val_size = len(custom_dataset) - train_size\n","train_dataset, val_dataset = random_split(custom_dataset, [train_size, val_size])\n","trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last = True)\n","validloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, drop_last = True)\n","del train_dataset, val_dataset, custom_dataset\n","'''"],"metadata":{"id":"uCpDwOmq2aBJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","# debug02\n","for batch in trainloader:\n","  # print(batch.keys())\n","  t = torch.randint(0, config['diffusion']['num_diffusion_timesteps'], (batch_size,)).long().to(device)\n","  input_img = batch['img'].to(torch.float32).to(device)\n","  input_img = image_loader_to_tensor(input_img)\n","  target_depth = batch['depth'].to(torch.float32).to(device)\n","  target_depth = depth_loader_to_tensor(target_depth, DEPTH_MEAN, DEPTH_STD)\n","  # print(t)\n","  # print(input_img.shape)\n","  # print(torch.max(input_img))\n","  # print(torch.max(target_depth[0]))\n","  pred_depth = model(input_img, target_depth, t)\n","  break\n","'''"],"metadata":{"id":"hCvNHt992cVn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# debug 04\n","# 接著可以每個dataset取一些值出來變成一個dataset來train\n","# data_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Data/data_zip'\n","# name_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Data/name_zip'\n","'''\n","data_path = '/content/drive/MyDrive/Colab Notebooks/共用區/Simple_DE/Data/data_zip'\n","name_path = '/content/drive/MyDrive/Colab Notebooks/共用區/Simple_DE/Data/name_zip'\n","data_list = sorted(os.listdir(data_path))\n","\n","new_image_list = []\n","new_depth_list = []\n","new_image_name_list = []\n","new_depth_name_list = []\n","data_list_length = len(data_list)\n","for idx in range(data_list_length):\n","  check = torch.load(data_path + '/' + data_list[idx])\n","  check_name = torch.load(name_path + '/' + data_list[idx])\n","  for jdx in range(294):\n","    random_number = random.randint(0, 4999)\n","    new_image_list.append(check['image_list'][random_number])\n","    new_depth_list.append(check['depth_list'][random_number])\n","    new_image_name_list.append(check_name['image_name'][random_number])\n","    new_depth_name_list.append(check_name['depth_name'][random_number])\n","\n","checkpoint = {\n","              'depth_list': new_depth_list,\n","              'image_list' : new_image_list,\n","          }\n","checkpoint2 = {\n","              'depth_name' : new_depth_name_list,\n","              'image_name' : new_image_name_list\n","          }\n","\n","name = 'dataset_new.pth'\n","name2 = 'name_list_new.pth'\n","torch.save(checkpoint, name)\n","torch.save(checkpoint2, name2)\n","\n","source_path = name\n","source_path2 = name2\n","destination_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Data/data_zip'    # 要改\n","destination_path2 = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Data/name_zip'\n","shutil.copy(source_path, destination_path)\n","shutil.copy(source_path2, destination_path2)\n","'''"],"metadata":{"id":"X0Zv6n-82eib"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","# debug 04\n","# 還有寫繼續train在大epoch還有哪些部分沒train完畢\n","# first epoch\n","epoch = 0\n","# data_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Data/data_zip'\n","# name_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Data/name_zip'\n","data_path = '/content/drive/MyDrive/Colab Notebooks/共用區/Simple_DE/Data/data_zip/dataset_new.pth'\n","\n","\n","\n","\n","check = torch.load(data_path)\n","output_depth = check['depth_list']\n","output_image = check['image_list']\n","custom_dataset = CustomDataset(output_image, output_depth)\n","train_size = int(0.9 * len(custom_dataset))\n","val_size = len(custom_dataset) - train_size\n","train_dataset, val_dataset = random_split(custom_dataset, [train_size, val_size])\n","trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last = True)\n","validloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, drop_last = True)\n","\n","\n","for now in range(100): # 一個小epoch是一個checkpoint檔，紀錄一次\n","\n","  epoch += 1\n","\n","\n","  start_time = time.time()\n","  mean_epoch_loss = []\n","  mean_epoch_loss_val = []\n","  epoch_gradient = {}\n","  for batch in trainloader:\n","      t = torch.randint(0, config['diffusion']['num_diffusion_timesteps'], (batch_size,)).long().to(device)\n","\n","      input_img = batch['img'].to(torch.float32).to(device)\n","      input_img = image_loader_to_tensor(input_img)\n","      target_depth = batch['depth'].to(torch.float32).to(device)\n","      target_depth = depth_loader_to_tensor(target_depth, DEPTH_MEAN, DEPTH_STD)\n","\n","      pred_depth = model(input_img, target_depth, t)\n","\n","      optimizer.zero_grad()\n","      loss = torch.nn.functional.mse_loss(target_depth, pred_depth)\n","      mean_epoch_loss.append(loss.item())\n","      loss.backward()\n","      optimizer.step()\n","\n","      # for name, param in model.named_pn arameters():\n","      #   if name not in epoch_gradient:\n","      #     epoch_gradient[name] = param.grad.clone()\n","      #   else:\n","      #     epoch_gradient[name] += param.grad\n","  with torch.inference_mode():\n","    for batch in validloader:\n","      t = torch.randint(0, config['diffusion']['num_diffusion_timesteps'], (batch_size,)).long().to(device)\n","      input_img = batch['img'].to(torch.float32).to(device)\n","\n","      input_img = image_loader_to_tensor(input_img)\n","      target_depth = batch['depth'].to(torch.float32).to(device)\n","      target_depth = depth_loader_to_tensor(target_depth, DEPTH_MEAN, DEPTH_STD)\n","      pred_depth = model(input_img, target_depth, t)\n","\n","      val_loss = torch.nn.functional.mse_loss(target_depth, pred_depth)\n","      mean_epoch_loss_val.append(val_loss.item())\n","\n","  if epoch % save_frequency == 0 :\n","    checkpoint = {\n","      'epoch': epoch,\n","      'model_state_dict': model.state_dict(), # model.state_dict()是存下param的的值和形狀\n","      'optimizer_state_dict': optimizer.state_dict(), # optimizer.state_dict()則是存下優化器的param如momentum等等 不包含當下梯度\n","      'valid_loss' : np.mean(mean_epoch_loss_val),\n","      'loss' : np.mean(mean_epoch_loss), # 記得不能存tensor\n","      # 'gradients' : epoch_gradient\n","    }\n","\n","    torch.save(checkpoint, 'weight_{}.pth'.format(epoch))\n","    source_path = 'weight_{}.pth'.format(epoch)\n","    destination_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Checkpoint/model1_weight_debug04'\n","\n","\n","    # save them to the google drive\n","    shutil.copy(source_path, destination_path)\n","\n","  #---計算時間---vvv\n","  end_time = time.time()\n","  exe_time = end_time - start_time\n","  hours, remainder = divmod(exe_time, 3600)\n","  minutes, seconds = divmod(remainder, 60)\n","  #---計算時間---^^^\n","\n","  #-----以下是存loss的---vvv\n","  checkpoint = {\n","    'epoch': epoch,\n","    'valid_loss' : np.mean(mean_epoch_loss_val),\n","    'loss' : np.mean(mean_epoch_loss), # 記得不能存tensor\n","    # 'time' : exe_time\n","  }\n","\n","  torch.save(checkpoint, 'loss_{}.pth'.format(epoch))\n","  source_path = 'loss_{}.pth'.format(epoch)\n","  destination_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Checkpoint/model1_loss_debug04'\n","\n","\n","  # save them to the google drive\n","  shutil.copy(source_path, destination_path)\n","  #-----以下是存loss的---^^^\n","\n","  print('---')\n","  print(f\"Epoch: {epoch} | Train Loss {np.mean(mean_epoch_loss)} | Val Loss {np.mean(mean_epoch_loss_val)}\")\n","  print(\"time = {}:{}:{}\".format(hours, minutes, seconds))\n","'''"],"metadata":{"id":"0kK6vdqv2hsz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","# debug 03\n","# 思考LOSS這樣的原因\n","# 可能是因為每個EPOCH自身的資料太相近\n","# 而EPOCH和EPOCH之間的資料又差距太大\n","# 試試看只對某個PTH做會發生什麼事情\n","epoch = 0\n","# data_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Data/data_zip'\n","# name_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Data/name_zip'\n","check_length = len(sorted(os.listdir(data_path)))\n","\n","random_list = []\n","large_epoch = 1\n","for idx in range(1, check_length + 1):\n","  random_list.append(idx)\n","\n","# random.shuffle(random_list)\n","\n","for now in range(100): # 一個小epoch是一個checkpoint檔，紀錄一次\n","\n","  epoch += 1\n","  if now == 0:\n","    output_image_path, output_depth_path, output_depth, output_image = create_dataset_large_epoch(random_list, 0, data_path, name_path)\n","  custom_dataset = CustomDataset(output_image, output_depth)\n","  train_size = int(0.9 * len(custom_dataset))\n","  val_size = len(custom_dataset) - train_size\n","  train_dataset, val_dataset = random_split(custom_dataset, [train_size, val_size])\n","  trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last = True)\n","  validloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, drop_last = True)\n","  start_time = time.time()\n","  mean_epoch_loss = []\n","  mean_epoch_loss_val = []\n","  epoch_gradient = {}\n","  for batch in trainloader:\n","      t = torch.randint(0, config['diffusion']['num_diffusion_timesteps'], (batch_size,)).long().to(device)\n","\n","      input_img = batch['img'].to(torch.float32).to(device)\n","      input_img = image_loader_to_tensor(input_img)\n","      target_depth = batch['depth'].to(torch.float32).to(device)\n","      target_depth = depth_loader_to_tensor(target_depth, DEPTH_MEAN, DEPTH_STD)\n","\n","      pred_depth = model(input_img, target_depth, t)\n","\n","      optimizer.zero_grad()\n","      loss = torch.nn.functional.mse_loss(target_depth, pred_depth)\n","      mean_epoch_loss.append(loss.item())\n","      loss.backward()\n","      optimizer.step()\n","\n","      # for name, param in model.named_pn arameters():\n","      #   if name not in epoch_gradient:\n","      #     epoch_gradient[name] = param.grad.clone()\n","      #   else:\n","      #     epoch_gradient[name] += param.grad\n","  with torch.inference_mode():\n","    for batch in validloader:\n","      t = torch.randint(0, config['diffusion']['num_diffusion_timesteps'], (batch_size,)).long().to(device)\n","      input_img = batch['img'].to(torch.float32).to(device)\n","\n","      input_img = image_loader_to_tensor(input_img)\n","      target_depth = batch['depth'].to(torch.float32).to(device)\n","      target_depth = depth_loader_to_tensor(target_depth, DEPTH_MEAN, DEPTH_STD)\n","      pred_depth = model(input_img, target_depth, t)\n","\n","      val_loss = torch.nn.functional.mse_loss(target_depth, pred_depth)\n","      mean_epoch_loss_val.append(val_loss.item())\n","\n","  if epoch % save_frequency == 0 or epoch == check_length * NO_LARGE_EPOCHS:\n","    checkpoint = {\n","      'large_epoch' : large_epoch,\n","      'epoch': epoch,\n","      'model_state_dict': model.state_dict(), # model.state_dict()是存下param的的值和形狀\n","      'optimizer_state_dict': optimizer.state_dict(), # optimizer.state_dict()則是存下優化器的param如momentum等等 不包含當下梯度\n","      'valid_loss' : np.mean(mean_epoch_loss_val),\n","      'loss' : np.mean(mean_epoch_loss), # 記得不能存tensor\n","      'now' : now\n","      # 'gradients' : epoch_gradient\n","    }\n","\n","    torch.save(checkpoint, 'weight_{}_{}.pth'.format(large_epoch, epoch))\n","    source_path = 'weight_{}_{}.pth'.format(large_epoch, epoch)\n","    destination_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Checkpoint/weight_save1'\n","\n","\n","    # save them to the google drive\n","    shutil.copy(source_path, destination_path)\n","\n","  #---計算時間---vvv\n","  end_time = time.time()\n","  exe_time = end_time - start_time\n","  hours, remainder = divmod(exe_time, 3600)\n","  minutes, seconds = divmod(remainder, 60)\n","  #---計算時間---^^^\n","\n","  #-----以下是存loss的---vvv\n","  checkpoint = {\n","    'large_epoch' : large_epoch,\n","    'epoch': epoch,\n","    'valid_loss' : np.mean(mean_epoch_loss_val),\n","    'loss' : np.mean(mean_epoch_loss), # 記得不能存tensor\n","    # 'time' : exe_time\n","  }\n","\n","  torch.save(checkpoint, 'loss_{}_{}.pth'.format(large_epoch, epoch))\n","  source_path = 'loss_{}_{}.pth'.format(large_epoch, epoch)\n","  destination_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Checkpoint/loss_save1'\n","\n","\n","  # save them to the google drive\n","  shutil.copy(source_path, destination_path)\n","  #-----以下是存loss的---^^^\n","\n","  print('---')\n","  print(f\"Large Epoch: {large_epoch}, Epoch: {epoch} | Train Loss {np.mean(mean_epoch_loss)} | Val Loss {np.mean(mean_epoch_loss_val)}\")\n","  print(\"time = {}:{}:{}\".format(hours, minutes, seconds))\n","  '''"],"metadata":{"id":"RTJyPi3o2kmO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# first epoch\n","'''\n","\n","\n","\n","for epoch in range(1, NO_EPOCHS + 1, 1):\n","    start_time = time.time()\n","    mean_epoch_loss = []\n","    mean_epoch_loss_val = []\n","    epoch_gradient = {}\n","    for batch in trainloader:\n","        t = torch.randint(0, config['diffusion']['num_diffusion_timesteps'], (batch_size,)).long().to(device)\n","\n","        input_img = batch['img'].to(torch.float32).to(device)\n","        target_depth = batch['depth'].to(torch.float32).to(device)\n","\n","        pred_depth = model(input_img, target_depth, t)\n","\n","        optimizer.zero_grad()\n","        loss = torch.nn.functional.mse_loss(target_depth, pred_depth)\n","        mean_epoch_loss.append(loss.item())\n","        loss.backward()\n","\n","\n","        for name, param in model.named_parameters():\n","          if name not in epoch_gradient:\n","            epoch_gradient[name] = param.grad.clone()\n","          else:\n","            epoch_gradient[name] += param.grad\n","        optimizer.step()\n","\n","    with torch.inference_mode():\n","      for batch in validloader:\n","        t = torch.randint(0, config['diffusion']['num_diffusion_timesteps'], (batch_size,)).long().to(device)\n","        input_img = batch['img'].to(torch.float32).to(device)\n","        target_depth = batch['depth'].to(torch.float32).to(device)\n","\n","        pred_depth = model(input_img, target_depth, t)\n","\n","        val_loss = torch.nn.functional.mse_loss(target_depth, pred_depth)\n","        mean_epoch_loss_val.append(val_loss.item())\n","\n","    if epoch % PRINT_FREQUENCY == 0 or epoch == NO_EPOCHS:\n","        checkpoint = {\n","          'epoch': epoch,\n","          'model_state_dict': model.state_dict(), # model.state_dict()是存下param的的值和形狀\n","          'optimizer_state_dict': optimizer.state_dict(), # optimizer.state_dict()則是存下優化器的param如momentum等等 不包含當下梯度\n","          'valid_loss' : np.mean(mean_epoch_loss_val),\n","          'loss' : np.mean(mean_epoch_loss), # 記得不能存tensor\n","          'gradients' : epoch_gradient\n","        }\n","\n","        torch.save(checkpoint, 'weight_{}.pth'.format(epoch))\n","        source_path = 'weight_{}.pth'.format(epoch)\n","        destination_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Checkpoint/weight_save'\n","\n","\n","        # save them to the google drive\n","        shutil.copy(source_path, destination_path)\n","\n","        #---計算時間---vvv\n","        end_time = time.time()\n","        exe_time = end_time - start_time\n","        hours, remainder = divmod(execution_time, 3600)\n","        minutes, seconds = divmod(remainder, 60)\n","        #---計算時間---^^^\n","\n","        #-----以下是存loss的---vvv\n","        checkpoint = {\n","          'epoch': epoch,\n","          'valid_loss' : np.mean(mean_epoch_loss_val),\n","          'loss' : np.mean(mean_epoch_loss), # 記得不能存tensor\n","          'time' : exe_time\n","        }\n","\n","        torch.save(checkpoint, 'loss_{}.pth'.format(epoch))\n","        source_path = 'loss_{}.pth'.format(epoch)\n","        destination_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Checkpoint/loss_save'\n","\n","\n","        # save them to the google drive\n","        shutil.copy(source_path, destination_path)\n","        #-----以下是存loss的---^^^\n","\n","        print('---')\n","        print(f\"Epoch: {epoch} | Train Loss {np.mean(mean_epoch_loss)} | Val Loss {np.mean(mean_epoch_loss_val)}\")\n","        print(\"time = {}:{}:{}\".format(hours, minutes, seconds))\n","'''"],"metadata":{"id":"TeZxK-wf20ss"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","# train_size = int(0.9 * len(custom_dataset))\n","# val_size = len(custom_dataset) - train_size\n","\n","\n","# train_dataset, val_dataset = random_split(custom_dataset, [train_size, val_size])\n","\n","# # 使用DataLoader加载数据集\n","# batch_size = 32\n","# trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last = True)\n","# validloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, drop_last = True)"],"metadata":{"id":"a6-kzqCi2-qc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(input_img.shape)\n","# print(target_depth.shape)\n","# print(t.shape)\n","# count = 0\n","# for batch in trainloader:\n","#   count = count + 1\n","# print(count)\n","# print(32 * 31)"],"metadata":{"id":"9oeoTSDt3AgH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# first epoch\n","'''\n","import shutil\n","\n","\n","for epoch in range(1, NO_EPOCHS + 1, 1):\n","    start_time = time.time()\n","    mean_epoch_loss = []\n","    mean_epoch_loss_val = []\n","    epoch_gradient = {}\n","    for batch in trainloader:\n","        t = torch.randint(0, config['diffusion']['num_diffusion_timesteps'], (batch_size,)).long().to(device)\n","\n","        input_img = batch['img'].to(torch.float32).to(device)\n","        target_depth = batch['depth'].to(torch.float32).to(device)\n","\n","        pred_depth = model(input_img, target_depth, t)\n","\n","        optimizer.zero_grad()\n","        loss = torch.nn.functional.mse_loss(target_depth, pred_depth)\n","        mean_epoch_loss.append(loss.item())\n","        loss.backward()\n","\n","\n","        for name, param in model.named_parameters():\n","          if name not in epoch_gradient:\n","            epoch_gradient[name] = param.grad.clone()\n","          else:\n","            epoch_gradient[name] += param.grad\n","        optimizer.step()\n","\n","    with torch.inference_mode():\n","      for batch in validloader:\n","        t = torch.randint(0, config['diffusion']['num_diffusion_timesteps'], (batch_size,)).long().to(device)\n","        input_img = batch['img'].to(torch.float32).to(device)\n","        target_depth = batch['depth'].to(torch.float32).to(device)\n","\n","        pred_depth = model(input_img, target_depth, t)\n","\n","        val_loss = torch.nn.functional.mse_loss(target_depth, pred_depth)\n","        mean_epoch_loss_val.append(val_loss.item())\n","\n","    if epoch % PRINT_FREQUENCY == 0 or epoch == NO_EPOCHS:\n","        checkpoint = {\n","          'epoch': epoch,\n","          'model_state_dict': model.state_dict(), # model.state_dict()是存下param的的值和形狀\n","          'optimizer_state_dict': optimizer.state_dict(), # optimizer.state_dict()則是存下優化器的param如momentum等等 不包含當下梯度\n","          'valid_loss' : np.mean(mean_epoch_loss_val),\n","          'loss' : np.mean(mean_epoch_loss), # 記得不能存tensor\n","          'gradients' : epoch_gradient\n","        }\n","\n","        torch.save(checkpoint, 'weight_{}.pth'.format(epoch))\n","        source_path = 'weight_{}.pth'.format(epoch)\n","        destination_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Checkpoint/weight_save'\n","\n","\n","        # save them to the google drive\n","        shutil.copy(source_path, destination_path)\n","\n","        #---計算時間---vvv\n","        end_time = time.time()\n","        exe_time = end_time - start_time\n","        hours, remainder = divmod(execution_time, 3600)\n","        minutes, seconds = divmod(remainder, 60)\n","        #---計算時間---^^^\n","\n","        #-----以下是存loss的---vvv\n","        checkpoint = {\n","          'epoch': epoch,\n","          'valid_loss' : np.mean(mean_epoch_loss_val),\n","          'loss' : np.mean(mean_epoch_loss), # 記得不能存tensor\n","          'time' : exe_time\n","        }\n","\n","        torch.save(checkpoint, 'loss_{}.pth'.format(epoch))\n","        source_path = 'loss_{}.pth'.format(epoch)\n","        destination_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Checkpoint/loss_save'\n","\n","\n","        # save them to the google drive\n","        shutil.copy(source_path, destination_path)\n","        #-----以下是存loss的---^^^\n","\n","        print('---')\n","        print(f\"Epoch: {epoch} | Train Loss {np.mean(mean_epoch_loss)} | Val Loss {np.mean(mean_epoch_loss_val)}\")\n","        print(\"time = {}:{}:{}\".format(hours, minutes, seconds))\n","'''"],"metadata":{"id":"wGHfcURm3F-2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import torch\n","# import shutil\n","# from google.colab import files\n","# initial = 16\n","# NO_EPOCHS = 200 # 要多做幾個epochs\n","# load_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Checkpoint/weight_save/weight_{}.pth'.format(initial) # 位置要改\n","# checkpoint = torch.load(load_path)"],"metadata":{"id":"6jUYmgb23H3-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# continue training\n","initial = 90\n","NO_EPOCHS = 20 # 要多做幾個epochs\n","load_path = '/content/drive/MyDrive/Colab Notebooks/共用區/Simple_DE/Checkpoint/weight_save/weight_{}.pth'.format(initial) # 位置要改\n","checkpoint = torch.load(load_path)\n","\n","start = checkpoint['epoch'] + 1\n","# model_state_dict = checkpoint['model_state_dict']\n","\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","for epoch in range(start , start + NO_EPOCHS + 1):\n","    start_time = time.time()\n","    epoch_gradient = {}\n","    mean_epoch_loss = []\n","    mean_epoch_loss_val = []\n","    for batch in trainloader:\n","        t = torch.randint(0, config['diffusion']['num_diffusion_timesteps'], (batch_size,)).long().to(device)\n","\n","        input_img = batch['img'].to(torch.float32).to(device)\n","        target_depth = batch['depth'].to(torch.float32).to(device)\n","\n","        pred_depth = model(input_img, target_depth, t)\n","\n","        optimizer.zero_grad()\n","        loss = torch.nn.functional.mse_loss(target_depth, pred_depth)\n","        mean_epoch_loss.append(loss.item())\n","        loss.backward()\n","\n","        for name, param in model.named_parameters():\n","          if name not in epoch_gradient:\n","            epoch_gradient[name] = param.grad.clone()\n","          else:\n","            epoch_gradient[name] += param.grad\n","\n","\n","        optimizer.step()\n","\n","    with torch.inference_mode():\n","      for batch in validloader:\n","        t = torch.randint(0, config['diffusion']['num_diffusion_timesteps'], (batch_size,)).long().to(device)\n","        input_img = batch['img'].to(torch.float32).to(device)\n","        target_depth = batch['depth'].to(torch.float32).to(device)\n","\n","        pred_depth = model(input_img, target_depth, t)\n","\n","        val_loss = torch.nn.functional.mse_loss(target_depth, pred_depth)\n","        mean_epoch_loss_val.append(val_loss.item())\n","\n","    if epoch % PRINT_FREQUENCY == 0 or epoch == start + NO_EPOCHS:\n","        checkpoint = {\n","          'epoch': epoch,\n","          'model_state_dict': model.state_dict(), # model.state_dict()是存下param的的值和形狀\n","          'optimizer_state_dict': optimizer.state_dict(), # optimizer.state_dict()則是存下優化器的param如momentum等等 不包含當下梯度\n","          'valid_loss' : np.mean(mean_epoch_loss_val),\n","          'loss' : np.mean(mean_epoch_loss), # 記得不能存tensor\n","          'gradients' : epoch_gradient\n","        }\n","\n","        torch.save(checkpoint, 'weight_{}.pth'.format(epoch))\n","        source_path = 'weight_{}.pth'.format(epoch)\n","        destination_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Checkpoint/weight_save_gradient_dev'\n","\n","\n","        # save them to the google drive\n","        shutil.copy(source_path, destination_path)\n","\n","\n","        #---計算時間---vvv\n","        end_time = time.time()\n","        exe_time = end_time - start_time\n","        hours, remainder = divmod(execution_time, 3600)\n","        minutes, seconds = divmod(remainder, 60)\n","        #---計算時間---^^^\n","        #-----以下是存loss的---vvv\n","        checkpoint = {\n","          'epoch': epoch,\n","          'valid_loss' : np.mean(mean_epoch_loss_val),\n","          'loss' : np.mean(mean_epoch_loss), # 記得不能存tensor\n","          'time' : exe_time\n","        }\n","\n","        torch.save(checkpoint, 'loss_{}.pth'.format(epoch))\n","        source_path = 'loss_{}.pth'.format(epoch)\n","        destination_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Checkpoint/loss_save_gradient_dev'\n","\n","\n","        # save them to the google drive\n","        shutil.copy(source_path, destination_path)\n","        #-----以下是存loss的---^^^\n","\n","\n","        print('---')\n","        print(f\"Epoch: {epoch} | Train Loss {np.mean(mean_epoch_loss)} | Val Loss {np.mean(mean_epoch_loss_val)}\")\n","        print(\"time = {}:{}:{}\".format(hours, minutes, seconds))"],"metadata":{"id":"loBygk9v3NPT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","import torch\n","import os\n","for idx in range(133):\n","  if idx == 45:\n","    continue\n","\n","  path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Checkpoint/loss_save/loss_{}.pth'.format(idx)\n","  check = torch.load(path)\n","  print(\"epoch : {}, loss = {}  | val_loss = {}\".format(check['epoch'], check['loss'], check['valid_loss']))\n","  print('----------')\n","\n","'''"],"metadata":{"id":"tWql3z_J3Pcy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","# continue training\n","# train for another account\n","# change the lr\n","\n","# continue training\n","# train for another account\n","# change the lr\n","\n","import shutil\n","from google.colab import files\n","initial = 100\n","NO_EPOCHS = 2000 # 要多做幾個epochs\n","load_path = '/content/drive/MyDrive/Colab Notebooks/共用區/Simple_DE/Checkpoint/weight_save_gradient_dev/weight_{}.pth'.format(initial) # 位置要改\n","checkpoint = torch.load(load_path)\n","\n","start = checkpoint['epoch'] + 1\n","# model_state_dict = checkpoint['model_state_dict']\n","\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","for epoch in range(start , start + NO_EPOCHS + 1):\n","    for param_group in optimizer.param_groups:\n","      param_group['lr'] = 0.0001\n","    epoch_gradient = {}\n","    mean_epoch_loss = []\n","    mean_epoch_loss_val = []\n","    for batch in trainloader:\n","        t = torch.randint(0, config['diffusion']['num_diffusion_timesteps'], (batch_size,)).long().to(device)\n","\n","        input_img = batch['img'].to(torch.float32).to(device)\n","        target_depth = batch['depth'].to(torch.float32).to(device)\n","\n","        pred_depth = model(input_img, target_depth, t)\n","\n","        optimizer.zero_grad()\n","        loss = torch.nn.functional.mse_loss(target_depth, pred_depth)\n","        mean_epoch_loss.append(loss.item())\n","        loss.backward()\n","\n","        for name, param in model.named_parameters():\n","          if name not in epoch_gradient:\n","            epoch_gradient[name] = param.grad.clone()\n","          else:\n","            epoch_gradient[name] += param.grad\n","\n","\n","        optimizer.step()\n","\n","    with torch.inference_mode():\n","      for batch in validloader:\n","        t = torch.randint(0, config['diffusion']['num_diffusion_timesteps'], (batch_size,)).long().to(device)\n","        input_img = batch['img'].to(torch.float32).to(device)\n","        target_depth = batch['depth'].to(torch.float32).to(device)\n","\n","        pred_depth = model(input_img, target_depth, t)\n","\n","        val_loss = torch.nn.functional.mse_loss(target_depth, pred_depth)\n","        mean_epoch_loss_val.append(val_loss.item())\n","\n","    if epoch % PRINT_FREQUENCY == 0 or epoch == start + NO_EPOCHS:\n","        checkpoint = {\n","          'epoch': epoch,\n","          'model_state_dict': model.state_dict(), # model.state_dict()是存下param的的值和形狀\n","          'optimizer_state_dict': optimizer.state_dict(), # optimizer.state_dict()則是存下優化器的param如momentum等等 不包含當下梯度\n","          'valid_loss' : np.mean(mean_epoch_loss_val),\n","          'loss' : np.mean(mean_epoch_loss), # 記得不能存tensor\n","          'gradients' : epoch_gradient\n","        }\n","\n","        torch.save(checkpoint, 'weight_{}.pth'.format(epoch))\n","        source_path = 'weight_{}.pth'.format(epoch)\n","        destination_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Checkpoint/weight_save'\n","\n","\n","        # save them to the google drive\n","        shutil.copy(source_path, destination_path)\n","\n","        #-----以下是存loss的---vvv\n","        checkpoint = {\n","          'epoch': epoch,\n","          'valid_loss' : np.mean(mean_epoch_loss_val),\n","          'loss' : np.mean(mean_epoch_loss) # 記得不能存tensor\n","        }\n","\n","        torch.save(checkpoint, 'loss_{}.pth'.format(epoch))\n","        source_path = 'loss_{}.pth'.format(epoch)\n","        destination_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Checkpoint/loss_save'\n","\n","\n","        # save them to the google drive\n","        shutil.copy(source_path, destination_path)\n","        #-----以下是存loss的---^^^\n","\n","\n","        print('---')\n","        print(f\"Epoch: {epoch} | Train Loss {np.mean(mean_epoch_loss)} | Val Loss {np.mean(mean_epoch_loss_val)}\")\n","'''"],"metadata":{"id":"iTlC-RD73R-V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","for idx in range(91, 111):\n","  path = '/content/drive/MyDrive/Colab Notebooks/共用區/Simple_DE/Checkpoint/loss_save_gradient_dev/loss_{}.pth'.format(idx)\n","'''"],"metadata":{"id":"ay83fBuQ3TzK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","# load gradient\n","epoch = 102\n","path = '/content/drive/MyDrive/Colab Notebooks/共用區/Simple_DE/Checkpoint/weight_save_gradient_dev/weight_{}.pth'.format(epoch)\n","check = torch.load(path, map_location = 'cpu')\n","'''"],"metadata":{"id":"LGi6Px2F3Xlf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","gradients = check['gradients']\n","torch.set_printoptions(precision=10)\n","\n","path\n","\n","for name, grad in gradients.items():\n","  # if name == 'fpn.ConvList.0.conv.bias':\n","    maximum = torch.max(grad)\n","    minimum = torch.min(grad)\n","    mean_val = torch.mean(grad)\n","    print(name, \" : \", grad.shape, \" | min = \", minimum, \" | max = \", maximum, \" | mean = \", mean_val)\n","    print(\"-----------------------\")\n","    # break\n","\n","torch.min(grad)\n","minimum\n","\n","torch.set_printoptions(precision=6)\n","print(maximum)\n","'''"],"metadata":{"id":"AyR6rktW3aji"},"execution_count":null,"outputs":[]}]}