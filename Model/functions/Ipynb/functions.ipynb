{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNX5RTS0bpPn+xvgUr8LasJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import cv2\n","import os\n","import numpy as np\n","import shutil\n","from google.colab.patches import cv2_imshow\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","import math\n","from PIL import Image\n","import torch.nn as nn\n","import yaml\n","import random\n","from google.colab import files\n","import sys\n","import time\n","from torch.utils.data import random_split\n","# from Model.Data_Process.data_processing import *\n","# from Model.Model1.model1_script import *"],"metadata":{"id":"6TMvRhL9eRIT"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nWO1H-0Et1Iy"},"outputs":[],"source":["def deb(param, str):\n","  print(str + \" = {}\".format(param))"]},{"cell_type":"code","source":["def load_config(file_path):\n","    with open(file_path, 'r') as file:\n","        config = yaml.safe_load(file)\n","    return config"],"metadata":{"id":"uJiZ_ifOt5D1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def count_params(model):\n","  sum = 0\n","  for param in model.parameters():\n","    sum = sum + param.numel()\n","  return sum"],"metadata":{"id":"Pg-k3oT3t_EO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","def find_next_file(first, second):\n","  first_list = sorted(os.listdir(first))\n","  second_list = sorted(os.listdir(second))\n","  length = len(first_list)\n","  while True:\n","    rand_int = random.randint(0, length - 1)\n","    target = first_list[rand_int]\n","    if target in second_list:\n","      return first + '/' + target, second + '/' + target\n","'''"],"metadata":{"id":"uvC9898IuFdc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sigmoid(x):\n","    return 1 / (np.exp(-x) + 1)"],"metadata":{"id":"rrBqfY3JsBEe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_beta_schedule(beta_schedule, *, beta_start, beta_end, num_diffusion_timesteps):\n","\n","\n","    if beta_schedule == \"quad\":\n","        betas = (\n","            np.linspace(\n","                beta_start ** 0.5,\n","                beta_end ** 0.5,\n","                num_diffusion_timesteps,\n","                dtype=np.float64,\n","            )\n","            ** 2\n","        )\n","    elif beta_schedule == \"linear\":\n","        betas = np.linspace(\n","            beta_start, beta_end, num_diffusion_timesteps, dtype=np.float64\n","        )\n","    elif beta_schedule == \"const\":\n","        betas = beta_end * np.ones(num_diffusion_timesteps, dtype=np.float64)\n","    elif beta_schedule == \"jsd\":  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n","        betas = 1.0 / np.linspace(\n","            num_diffusion_timesteps, 1, num_diffusion_timesteps, dtype=np.float64\n","        )\n","    elif beta_schedule == \"sigmoid\":\n","        betas = np.linspace(-6, 6, num_diffusion_timesteps)\n","        betas = sigmoid(betas) * (beta_end - beta_start) + beta_start\n","    else:\n","        raise NotImplementedError(beta_schedule)\n","    assert betas.shape == (num_diffusion_timesteps,)\n","    return betas"],"metadata":{"id":"EVn5hTCquM_b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compute_alpha(beta, t): # t給tensor 一維的\n","    beta = torch.cat([torch.zeros(1).to(beta.device), beta], dim=0)\n","    a = (1 - beta).cumprod(dim=0).index_select(0, t + 1).view(-1, 1, 1, 1)\n","    return a"],"metadata":{"id":"SwLQT0T21G3v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_timestep_embedding(timesteps, embedding_dim):\n","\n","    assert len(timesteps.shape) == 1\n","\n","    half_dim = embedding_dim // 2\n","    emb = math.log(10000) / (half_dim - 1)\n","    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n","    emb = emb.to(device=timesteps.device)\n","    emb = timesteps.float()[:, None] * emb[None, :]\n","    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n","    if embedding_dim % 2 == 1:  # zero pad\n","        emb = torch.nn.functional.pad(emb, (0, 1, 0, 0))\n","    return emb"],"metadata":{"id":"53v82GWw1ImH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for the batch normalization\n","def Normalize(input, channels, momentum = 0.1, epsilon = 1e-5):\n","  bn = nn.BatchNorm2d(channels, momentum = momentum, eps = epsilon)\n","  return bn(input)"],"metadata":{"id":"5wbmNcUp1NzN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def nonlinearity(x):\n","\n","    return x*torch.sigmoid(x)\n"],"metadata":{"id":"zw8dtn041SGt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def Normalize(in_channels):\n","    return torch.nn.GroupNorm(num_groups=32, num_channels=in_channels, eps=1e-6, affine=True)"],"metadata":{"id":"AUiBVH1x1WbR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_index_from_list(values, t, x_shape):\n","    batch_size = t.shape[0]\n","    \"\"\"\n","    pick the values from vals\n","    according to the indices stored in `t`\n","    \"\"\"\n","    result = values.gather(-1, t.cpu())\n","    \"\"\"\n","    if\n","    x_shape = (5, 3, 64, 64)\n","        -> len(x_shape) = 4\n","        -> len(x_shape) - 1 = 3\n","\n","    and thus we reshape `out` to dims\n","    (batch_size, 1, 1, 1)\n","\n","    \"\"\"\n","    return result.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)"],"metadata":{"id":"pUsYSFLx1eYn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","def training(start_epoch, steps, load_path, model, PRINT_FREQUENCY,  optimizer, save_frequency, trainloader, validloader, datasets_path, batch_size, config, device, weights_save_path, loss_save_path, gradient_save_path = None, save_gradient = False): # load path is where the already existed weights save\n","  initial = start_epoch\n","\n","  NO_EPOCHS = steps # 要多做幾個epochs\n","  # load_path = '/content/drive/MyDrive/Colab Notebooks/共用區/Simple_DE/Checkpoint/weight_save/weight_{}.pth'.format(initial) # 位置要改\n","  checkpoint = torch.load(load_path)\n","\n","  start = checkpoint['epoch'] + 1\n","  # model_state_dict = checkpoint['model_state_dict']\n","\n","  model.load_state_dict(checkpoint['model_state_dict'])\n","  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","  for epoch in range(start , start + NO_EPOCHS + 1):\n","      start_time = time.time()\n","      epoch_gradient = {}\n","      mean_epoch_loss = []\n","      mean_epoch_loss_val = []\n","      for batch in trainloader:\n","          t = torch.randint(0, config['diffusion']['num_diffusion_timesteps'], (batch_size,)).long().to(device)\n","\n","          input_img = batch['img'].to(torch.float32).to(device)\n","          target_depth = batch['depth'].to(torch.float32).to(device)\n","\n","          pred_depth = model(input_img, target_depth, t)\n","\n","          optimizer.zero_grad()\n","          loss = torch.nn.functional.mse_loss(target_depth, pred_depth)\n","          mean_epoch_loss.append(loss.item())\n","          loss.backward()\n","\n","          if save_gradient :\n","            for name, param in model.named_parameters():\n","              if name not in epoch_gradient:\n","                epoch_gradient[name] = param.grad.clone()\n","              else:\n","                epoch_gradient[name] += param.grad\n","\n","\n","          optimizer.step()\n","\n","      with torch.inference_mode():\n","        for batch in validloader:\n","          t = torch.randint(0, config['diffusion']['num_diffusion_timesteps'], (batch_size,)).long().to(device)\n","          input_img = batch['img'].to(torch.float32).to(device)\n","          target_depth = batch['depth'].to(torch.float32).to(device)\n","\n","          pred_depth = model(input_img, target_depth, t)\n","\n","          val_loss = torch.nn.functional.mse_loss(target_depth, pred_depth)\n","          mean_epoch_loss_val.append(val_loss.item())\n","\n","      if epoch % save_frequency == 0 or epoch == start + NO_EPOCHS:\n","          checkpoint = {\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(), # model.state_dict()是存下param的的值和形狀\n","            'optimizer_state_dict': optimizer.state_dict(), # optimizer.state_dict()則是存下優化器的param如momentum等等 不包含當下梯度\n","            'valid_loss' : np.mean(mean_epoch_loss_val),\n","            'loss' : np.mean(mean_epoch_loss) # 記得不能存tensor\n","          }\n","\n","          torch.save(checkpoint, 'weight_{}.pth'.format(epoch))\n","          source_path = 'weight_{}.pth'.format(epoch)\n","          destination_path = weights_save_path\n","\n","\n","          # save them to the google drive\n","          shutil.copy(source_path, destination_path)\n","          #---計算時間---vvv\n","          end_time = time.time()\n","          exe_time = end_time - start_time\n","          hours, remainder = divmod(execution_time, 3600)\n","          minutes, seconds = divmod(remainder, 60)\n","          #---計算時間---^^^\n","          #-----以下是存loss的---vvv\n","          checkpoint = {\n","            'epoch': epoch,\n","            'valid_loss' : np.mean(mean_epoch_loss_val),\n","            'loss' : np.mean(mean_epoch_loss), # 記得不能存tensor\n","            'time' : exe_time\n","          }\n","\n","          torch.save(checkpoint, 'loss_{}.pth'.format(epoch))\n","          source_path = 'loss_{}.pth'.format(epoch)\n","          destination_path = loss_save_path\n","          #-----存gradient---vvv\n","          if save_gradient:\n","            checkpoint = {\n","            'gradients' : epoch_gradient\n","          }\n","          torch.save(checkpoint, 'gradient_{}.pth'.format(epoch))\n","          source_path = 'gradient_{}.pth'.format(epoch)\n","          destination_path = gradient_save_path\n","          shutil.copy(source_path, destination_path)\n","\n","          #-----存gradient---^^^\n","          # save them to the google drive\n","          shutil.copy(source_path, destination_path)\n","          #-----以下是存loss的---^^^\n","\n","        if epoch % PRINT_FREQUENCY == 0:\n","          print('---')\n","          print(f\"Epoch: {epoch} | Train Loss {np.mean(mean_epoch_loss)} | Val Loss {np.mean(mean_epoch_loss_val)}\")\n","          print(\"time = {}:{}:{}\".format(hours, minutes, seconds))\n","'''"],"metadata":{"id":"3GZScmKi3C_W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Model_optimize:\n","    def __init__(self, model, weight_path, loaded = False):\n","        if loaded == False:\n","            checkpoint = torch.load(weight_path, map_location=torch.device(device))\n","            model.load_state_dict(checkpoint['model_state_dict'])\n","        self.model = model\n","        count = 0\n","        for name, param in model.named_parameters():\n","            count += 1\n","        self.amount_of_param = count\n","    def find_a_parameter(self, target):\n","        list = []\n","\n","        for name, param in model.named_parameters():\n","            par_shape = len(param.shape)\n","            if par_shape == 1:\n","                if param[0] == target:\n","                    list.append(name)\n","            elif par_shape == 2:\n","                if param[0][0] == target:\n","                    list.append(name)\n","            elif par_shape == 3:\n","                if param[0][0][0] == target:\n","                    list.append(name)\n","            elif par_shape == 4:\n","                if param[0][0][0][0] == target:\n","                    list.append(name)\n","        return list\n","    def analyst_param(self):\n","        for name, param in model.named_parameters():\n","            print('{} | {}'.format(name, param))\n","            print('--------------------------')\n","    def list_name(self):\n","        for name, param in model.named_parameters():\n","            print(name)\n","            print('--------------------------')\n","    def statics(self):\n","        for name, param in model.named_parameters():\n","            print('{} | max = {} | min = {} | mean = {}'.format(name, torch.max(param), torch.min(param), torch.mean(param)))\n","    def plot_name(self, name):\n","        for names, param in model.named_parameters():\n","            if names == name:\n","                weights_list = param.data.cpu().numpy().flatten()\n","                plt.figure(figsize=(7, 5))\n","                plt.title('Weight Distribution')\n","                plt.hist(weights_list, bins=50, alpha=0.7)\n","                plt.xlabel('Weight Value')\n","                plt.ylabel('Frequency')\n","                plt.show()\n","\n","                break\n","    def plot_idx(self, idx):\n","        count = 0\n","        for names, param in model.named_parameters():\n","            if count == idx:\n","                weights_list = param.data.cpu().numpy().flatten()\n","                plt.figure(figsize=(7, 5))\n","                plt.title(names)\n","                plt.hist(weights_list, bins=50, alpha=0.7)\n","                plt.xlabel('Weight Value')\n","                plt.ylabel('Frequency')\n","                plt.show()\n","\n","                break\n","            count += 1\n","    def plot_whole_sep(self):\n","        for idx in range(self.amount_of_param):\n","            self.plot_idx(idx)\n","\n","    def plot_whole(self):\n","        weights_list = []\n","        for name, param in model.named_parameters():\n","            weights_list.append(param.data.cpu().numpy().flatten())\n","        plt.figure(figsize=(7, 5))\n","        plt.title('whole_plot')\n","        plt.hist(weights_list, bins=50, alpha=0.7)\n","        plt.xlabel('Weight Value')\n","        plt.ylabel('Frequency')\n","        plt.show()"],"metadata":{"id":"7opP5EhM-gaw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Model_optimize_comp:\n","    def __init__(self, Model, config, weight_path1, weight_path2, loaded = False):\n","        if loaded == False:\n","            checkpoint = torch.load(weight_path1, map_location=torch.device(device))\n","            self.grad1 = checkpoint['gradients']\n","            model = Model(config)\n","            model.load_state_dict(checkpoint['model_state_dict'])\n","            self.model1 = model\n","            del model\n","            model = Model(config)\n","            checkpoint = torch.load(weight_path2, map_location=torch.device(device))\n","            self.grad2 = checkpoint['gradients']\n","            model.load_state_dict(checkpoint['model_state_dict'])\n","            self.model2 = model\n","\n","        count = 0\n","        for name, param in self.model1.named_parameters():\n","            count += 1\n","        self.amount_of_param = count\n","    def list_name(self):\n","        for name, param in self.model1.named_parameters():\n","            print(name)\n","            print('--------------------------')\n","    def statics(self):\n","        for name, param in self.model1.named_parameters():\n","            for name2, param2 in self.model2.named_parameters():\n","                if name2 == name:\n","                    break\n","            print('{} | max = {} | min = {} | mean = {}'.format(name, torch.max(param), torch.min(param), torch.mean(param)))\n","            print('{} | max = {} | min = {} | mean = {}'.format(name, torch.max(param2), torch.min(param2), torch.mean(param2)))\n","    def plot_name(self, name):\n","        for names, param in self.model1.named_parameters():\n","            if names == name:\n","                weights_list = param.data.cpu().numpy().flatten()\n","                plt.figure(figsize=(7, 5))\n","                plt.title('Weight Distribution')\n","                plt.hist(weights_list, bins=50, alpha=0.7)\n","                plt.xlabel('Weight Value')\n","                plt.ylabel('Frequency')\n","                plt.show()\n","\n","                break\n","    def plot_idx(self, idx):\n","        count = 0\n","        for names, param in self.model1.named_parameters():\n","            for names2, param2 in self.model2.named_parameters():\n","                if names2 == names:\n","                    break\n","            if count == idx:\n","                weights_list1 = param.data.cpu().numpy().flatten()\n","                weights_list2 = param2.data.cpu().numpy().flatten()\n","\n","                plt.figure(figsize=(10, 5))\n","                plt.subplot(1, 2, 1)\n","                plt.title(names)\n","                mini = torch.min(weights_list1)\n","                maxi = torch.max(weights_list1)\n","                plt.xlim(mini, maxi)\n","                plt.hist(weights_list1, bins=50, alpha=0.7)\n","                plt.subplot(1, 2, 2)\n","                plt.title(names)\n","                plt.xlim(mini, maxi)\n","                plt.hist(weights_list2, bins=50, alpha=0.7)\n","                plt.show()\n","\n","                break\n","            count += 1\n","    def plot_whole_sep(self):\n","        for idx in range(self.amount_of_param):\n","            self.plot_idx(idx)\n","\n","    def ana_comp(self):\n","        for names, param in self.model1.named_parameters():\n","            for names2, param2 in self.model2.named_parameters():\n","                if names2 == names:\n","                    break\n","            max_ratio = torch.max(param) / torch.max(param2)\n","            min_ratio = torch.min(param) / torch.min(param2)\n","            mean_ratio = torch.mean(param) / torch.mean(param2)\n","            std_ratio = torch.std(param) / torch.std(param2)\n","            print('name = {} | max ratio = {} | min ratio = {} | mean ratio = {} | std ratio = {}'.format(names, max_ratio, min_ratio, mean_ratio, std_ratio))\n","    def grad_comp(self):\n","        for keys in self.grad1:\n","            max_ratio = torch.max(self.grad1[keys]) / torch.max(self.grad2[keys])\n","            min_ratio = torch.min(self.grad1[keys]) / torch.min(self.grad2[keys])\n","            mean_ratio = torch.mean(self.grad1[keys]) / torch.mean(self.grad2[keys])\n","            std_ratio = torch.std(self.grad1[keys]) / torch.std(self.grad2[keys])\n","            print('name = {} | max ratio = {} | min ratio = {} | mean ratio = {} | std ratio = {}'.format(keys, max_ratio, min_ratio, mean_ratio, std_ratio))\n","\n","\n","    def print_grad(self):\n","        for keys, values in self.grad2.items():\n","            print('{} : {}'.format(keys, values))\n","    def show_count(self):\n","        print(self.amount_of_param)"],"metadata":{"id":"e7NQx6Do-jPn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","count = 0\n","path_list = []\n","for large_epoch in range(1, 4):\n","\n","    while True:\n","        count += 1\n","        path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Checkpoint/drawing_weight/weight_{}_{}.pth'.format(large_epoch, count)\n","        path_list.append(path)\n","        if count % 18 == 0:\n","            break\n","\n","path_list\n","'''"],"metadata":{"id":"WNQE56z8-mGs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class plot:\n","    def __init__(self, path_list):\n","        self.path_list = path_list\n","        # checkpoint = torch.load(path, map_location=torch.device(device))\n","        # self.grad1 = checkpoint['gradients']\n","        # model = Model(config)\n","        # model.load_state_dict(checkpoint['model_state_dict'])\n","        # self.model1 = model\n","        # self.path_list = path_list\n","        # del model\n","        # model = Model(config)\n","        # # checkpoint = torch.load(weight_path2, map_location=torch.device(device))\n","        # self.grad2 = checkpoint['gradients']\n","        # model.load_state_dict(checkpoint['model_state_dict'])\n","        # self.model2 = model\n","\n","        # count = 0\n","        # for name, param in self.model1.named_parameters():\n","        #     count += 1\n","        # self.amount_of_param = count\n","    def draw_grad(self, epoch_interval, param_interval, legend = True):\n","        output_list = [] # row代表不同的epochs column代表不同的params\n","        keys_list = []\n","        count = 0\n","        x_coor = []\n","        for idx in range(epoch_interval[0], epoch_interval[1]):\n","            x_coor.append(idx)\n","            file = self.path_list[idx] # traverse epoch\n","            tmp_list = []\n","            check = torch.load(file, map_location = torch.device(device))\n","            grad = check['gradients']\n","            if count == 0:\n","                count += 1\n","                keys_list = list(grad.keys())\n","                keys_list = keys_list[param_interval[0] : param_interval[1]]\n","            for key in keys_list:\n","                summ = torch.mean(torch.abs(grad[key]))\n","                tmp_list.append(summ)\n","            output_list.append(tmp_list)\n","        plt.figure(figsize=(8, 6))  # 设置图形大小\n","        for col in range(len(output_list[0])):\n","            column_data = []\n","            for row in output_list:\n","                column_data.append(row[col])\n","            plt.plot(x_coor, column_data, label=keys_list[col])\n","\n","        plt.xlabel('Epochs')  # 设置 x 轴标签\n","        plt.ylabel('Values')  # 设置 y 轴标签\n","        plt.title('Lines for Each Column')  # 设置标题\n","        if legend:\n","            plt.legend()  # 添加图例\n","        plt.grid(True)  # 添加网格线\n","        plt.show()  # 显示图形\n","    def count_param(self):\n","        file = self.path_list[0]\n","        check = torch.load(file, map_location = torch.device(device))\n","        grad = check['gradients']\n","        keys_list = list(grad.keys())\n","        print(\"there are {} many gradients groups\".format(len(keys_list)))\n","\n","\n","\n"],"metadata":{"id":"WjBBwFeY-qo4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","plotting = plot(path_list)\n","epoch_interval = [1, 20]\n","for idx in range(50):\n","    param_interval = [idx * 10, (idx + 1) * 10]\n","    plotting.draw_grad(epoch_interval, param_interval, legend = False)\n","'''"],"metadata":{"id":"uv3PF0LY-sZj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","plotting = plot(path_list)\n","epoch_interval = [20, 50]\n","for idx in range(50):\n","    param_interval = [idx * 10, (idx + 1) * 10]\n","    plotting.draw_grad(epoch_interval, param_interval, legend = False)\n","'''"],"metadata":{"id":"OKEFGLPB-yuX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","#reference mode\n","\n","beta_schedule = config['diffusion']['beta_schedule']\n","start_schedule = config['diffusion']['beta_start']\n","end_schedule = config['diffusion']['beta_end']\n","timesteps = config['diffusion']['num_diffusion_timesteps']\n","diff = DiffusionModel(beta_schedule, start_schedule, end_schedule, timesteps)\n","model = Model(config)\n","model = model.to(device)\n","ans1, ans2 = diff.backward(model, img, weight_path, 1) # img should have 4 dimension\n","'''"],"metadata":{"id":"CSAIG7pJ_Cch"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","# convert back into depth map\n","with torch.inference_mode():\n","    final_ans = tensor_to_depth(depth2, DEPTH_MEAN, DEPTH_STD)\n","    final_ans = torch.squeeze(final_ans, dim = 0).to('cpu').numpy()\n","'''"],"metadata":{"id":"vcdm8JmW_E0V"},"execution_count":null,"outputs":[]}]}